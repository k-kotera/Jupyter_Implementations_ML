{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ModelSeeking_cDCGAN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/k-kotera/Jupyter_Implementations_ML/blob/master/ModelSeekingGAN_keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "NWXyYONt-zSC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Mode Seeking Generative Adversarial Networks for Diverse Image Synthesis\n",
        "\n",
        "#### 参考\n",
        "Qi Mao, Hsin-Ying Lee, Hung-Yu Tseng, Siwei Ma, Ming-Hsuan Yang.\n",
        "Mode Seeking Generative Adversarial Networks for Diverse Image Synthesis.\n",
        "https://arxiv.org/pdf/1903.05628v1.pdf"
      ]
    },
    {
      "metadata": {
        "id": "O_idq2xHPIV6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "69aa9e1b-b547-4a65-8e7a-f54388de5681"
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import cifar10\n",
        "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, concatenate, Lambda\n",
        "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.layers.convolutional import UpSampling2D, Conv2D, Conv2DTranspose\n",
        "from keras.models import Sequential, Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import to_categorical\n",
        "from keras import backend as K\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "slp6-yWrPg3c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#parameters\n",
        "batch_size = 100\n",
        "latent_dim = 100\n",
        "condition_dim = 10# =num_of_classes\n",
        "Height = 32\n",
        "Width = 32\n",
        "Channels = 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T2gvXCeNPjsQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "2006b386-5dd5-4329-e47e-5941883c49f8"
      },
      "cell_type": "code",
      "source": [
        "#Generator_model\n",
        "in_h = int(Height / 4)\n",
        "in_w = int(Width / 4)\n",
        "\n",
        "# latent vector input\n",
        "generator_input1 = Input(shape=(latent_dim,))\n",
        "# condition input\n",
        "generator_input2 = Input(shape=(condition_dim,))\n",
        "generator_input2_copy = Activation('linear')(generator_input2)\n",
        "# concat 2 inputs\n",
        "generator_input = concatenate([generator_input1, generator_input2])\n",
        "\n",
        "x = Dense(in_h * in_w * 128, activation='tanh', name='g_dense1')(generator_input)\n",
        "x = BatchNormalization()(x)\n",
        "x = Reshape((in_h, in_w, 128))(x)\n",
        "\n",
        "x = Conv2DTranspose(64, kernel_size=4, strides=2, padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "x = Conv2DTranspose(3, kernel_size=4, strides=2, padding='same')(x)\n",
        "x = Activation('tanh')(x)\n",
        "\n",
        "Generator = Model(inputs=[generator_input1, generator_input2], outputs=[x, generator_input2_copy], name=\"Generator\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BiJScBgGX7Z2",
        "colab_type": "code",
        "outputId": "8769ccf3-2111-403b-ce0e-b8e861525add",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "cell_type": "code",
      "source": [
        "Generator.summary()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 100)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            (None, 10)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 110)          0           input_1[0][0]                    \n",
            "                                                                 input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "g_dense1 (Dense)                (None, 8192)         909312      concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 8192)         32768       g_dense1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "reshape_1 (Reshape)             (None, 8, 8, 128)    0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTrans (None, 16, 16, 64)   131136      reshape_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 16, 16, 64)   256         conv2d_transpose_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTrans (None, 32, 32, 3)    3075        batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 32, 32, 3)    0           conv2d_transpose_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 10)           0           input_2[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 1,076,547\n",
            "Trainable params: 1,060,035\n",
            "Non-trainable params: 16,512\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uit9fOyuYSyJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Discriminator_model\n",
        "\n",
        "discriminator_input1 = Input(shape=(Height, Width, Channels))\n",
        "discriminator_input2 = Input(shape=(condition_dim,))\n",
        "\n",
        "discriminator_input2_r = Reshape((1, 1, condition_dim))(discriminator_input2)\n",
        "discriminator_input2_r = UpSampling2D((Height, Width))(discriminator_input2_r)\n",
        "\n",
        "discriminator_input = concatenate([discriminator_input1, discriminator_input2_r])\n",
        "x = Conv2D(64, kernel_size=4, strides=2, padding='same')(discriminator_input)\n",
        "x = BatchNormalization()(x)\n",
        "x = LeakyReLU(alpha=0.2)(x)\n",
        "x = Conv2D(128, kernel_size=4, strides=2, padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = LeakyReLU(alpha=0.2)(x)\n",
        "x = Conv2D(256, kernel_size=4, strides=2, padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = LeakyReLU(alpha=0.2)(x)\n",
        "x = Conv2D(256, kernel_size=4, strides=2)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "x = Flatten()(x)\n",
        "x = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "Discriminator = Model(inputs=[discriminator_input1, discriminator_input2], outputs=x)\n",
        "\n",
        "Discriminator.compile(loss='binary_crossentropy',\n",
        "            optimizer='SGD',\n",
        "            metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DnIrKjWTMd3_",
        "colab_type": "code",
        "outputId": "d29fb6b5-9ac0-47be-ceb9-e3283fa02232",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        }
      },
      "cell_type": "code",
      "source": [
        "Discriminator.summary()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_4 (InputLayer)            (None, 10)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "reshape_2 (Reshape)             (None, 1, 1, 10)     0           input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2D)  (None, 32, 32, 10)   0           reshape_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 32, 32, 13)   0           input_3[0][0]                    \n",
            "                                                                 up_sampling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 16, 16, 64)   13376       concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 16, 16, 64)   256         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)       (None, 16, 16, 64)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 8, 8, 128)    131200      leaky_re_lu_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 8, 8, 128)    512         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)       (None, 8, 8, 128)    0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 4, 4, 256)    524544      leaky_re_lu_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 4, 4, 256)    1024        conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)       (None, 4, 4, 256)    0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 1, 1, 256)    1048832     leaky_re_lu_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 1, 1, 256)    1024        conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)       (None, 1, 1, 256)    0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 256)          0           leaky_re_lu_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1)            257         flatten_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 1,721,025\n",
            "Trainable params: 1,719,617\n",
            "Non-trainable params: 1,408\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gOfFy9iCMkMO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#GAN_model\n",
        "Discriminator.trainable = False\n",
        "gan_input1 = Input(shape=(latent_dim,))\n",
        "gan_input2 = Input(shape=(condition_dim,))\n",
        "gen_img = Generator([gan_input1, gan_input2])\n",
        "gan_output = Discriminator(gen_img)\n",
        "Gan = Model([gan_input1, gan_input2], gan_output)\n",
        "\n",
        "gan_input_half1 = Lambda(lambda x: x[:int(batch_size/2)], output_shape=(latent_dim,))(gan_input1)\n",
        "gan_input_half2 = Lambda(lambda x: x[int(batch_size/2):], output_shape=(latent_dim,))(gan_input1)\n",
        "\n",
        "gen_img_half1 = Lambda(lambda x: x[:int(batch_size/2)], output_shape=(Height,Width,Channels))(gen_img[0])\n",
        "gen_img_half2 = Lambda(lambda x: x[int(batch_size/2):], output_shape=(Height,Width,Channels))(gen_img[0])\n",
        "\n",
        "alpha = 1\n",
        "def gan_loss(y_true, y_pred):\n",
        "    lz = K.mean(K.abs((gen_img_half1 - gen_img_half2)))/K.mean(K.abs((gan_input_half1 - gan_input_half2)))\n",
        "    eps = 1e-6\n",
        "    loss_lz = 1 / (lz + eps)\n",
        "    return K.binary_crossentropy(y_true, y_pred) + alpha*loss_lz\n",
        "\n",
        "Gan.compile(loss=gan_loss,\n",
        "            optimizer='SGD',\n",
        "            metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wVsAN0_nQtO7",
        "colab_type": "code",
        "outputId": "3f7137b0-e0a6-41cb-ad0d-91af01a62d21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "cell_type": "code",
      "source": [
        "Gan.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_5 (InputLayer)            (None, 100)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_6 (InputLayer)            (None, 10)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Generator (Model)               [(None, 32, 32, 3),  1076547     input_5[0][0]                    \n",
            "                                                                 input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "model_1 (Model)                 (None, 1)            1721025     Generator[1][0]                  \n",
            "                                                                 Generator[1][1]                  \n",
            "==================================================================================================\n",
            "Total params: 2,797,572\n",
            "Trainable params: 1,060,035\n",
            "Non-trainable params: 1,737,537\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qkFvnnvTLnmV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Load_cifar10dataset\n",
        "(X_train, Y_train), (_, _) = cifar10.load_data()\n",
        "Y_train_c = to_categorical(Y_train, 10)\n",
        "X_train = X_train.reshape((X_train.shape[0],) + (Height, Width, Channels)).astype('float32')\n",
        "X_train = (X_train - 127.5) / 127.5\n",
        "\n",
        "valid_labels = np.ones((batch_size, 1))\n",
        "fake_labels = np.zeros((batch_size, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rR83sjnbvlT7",
        "colab_type": "code",
        "outputId": "5b0d6491-6c0f-4b41-ca23-5e57aabd36fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#Training\n",
        "for epoch in tqdm(range(10000)):\n",
        "    idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
        "    imgs, labels = X_train[idx], Y_train_c[idx]\n",
        "    random_latent_vectors = np.random.normal(0, 1, (batch_size, latent_dim))\n",
        "    generated_images = Generator.predict([random_latent_vectors, labels])\n",
        "\n",
        "    # Train the discriminator\n",
        "    d_loss_real = Discriminator.train_on_batch([imgs, labels], valid_labels)\n",
        "    d_loss_fake = Discriminator.train_on_batch(generated_images, fake_labels)\n",
        "    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "    # Train the discriminator\n",
        "    sampled_labels = to_categorical(np.random.randint(0, condition_dim, batch_size).reshape(-1, 1), num_classes=condition_dim)\n",
        "    g_loss = Gan.train_on_batch([random_latent_vectors,  sampled_labels], valid_labels)"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10000/10000 [07:09<00:00, 23.27it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "XvlRUjQp5PGn",
        "colab_type": "code",
        "outputId": "ea775e2f-d56e-4f98-c6de-7c28b1e8242b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "cell_type": "code",
      "source": [
        "random_latent_vectors = np.random.normal(0, 1, (1, latent_dim))\n",
        "condition = np.array(to_categorical([5], 10))\n",
        "gen_image = Generator.predict([random_latent_vectors, condition])[0][0]\n",
        "\n",
        "any_gen_image = np.array(gen_image*127.5+127.5,int)\n",
        "plt.imshow(any_gen_image)"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fe03fd3d080>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 142
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}